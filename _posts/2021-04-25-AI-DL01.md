---
layout: post
title: "AI: Deep Learning-01"
date: 2021-04-25
categories:
  - AI
tags:
  - deep learning
  - basic
author_profile: true
read_time: true
comments: true
share: true
related: true
popular: true
toc: true
toc_sticky: true
toc_label: 목차
article_tag1: deep learning
article_tag2: basic
article_section: AI
meta_keywords: AI, deep learning, basic
published: true
---

## AI: Deep Learning 01

- Basic words
  - Data
    - Model's input
    - Data augmentation is important for big data
    - Make Batch before getting into model

  - Model
    - Architecture such as LeNet, AlexNet, VGG, ResNet, etc.
    - Composed w/ layers such as Convolution Layer, Pooling, etc
    - Need to tune weights to get best features

  - Prediction / Logit
    - Predicted value for each class
    > [0.15, 0.2, 0.6, 0.05] or [0.0, 0.0, 0.0, 1.0]
    - Larger value -> more correct answer

  - Loss / Cost
    - Loss function: Get difference (loss/cost) between predicted value and actual value
    - There's a lot of Loss Function such as Cross Entropy
    - Learning in order to minimize Loss

  - Optimization
    - Minimize Loss
    - Does not apply optimized value but value w/ learning rate

  - Result
    - From predicted values, get max value using argmax

  - Layer
    - Input layer - Hidden Layers - Ouput layer
    - VGG16 : 16 layers
    - Not necessarily deeper the better
      - May cause over-fitting
      - Slower
      - Heavy

  - Weight / Filter / Kernel / Variable / Bias

  y = W(eight)x + b(ias)

  - Convolution: Get feature
  - Pooling: Zip feature to exagarate it

  - Activation Function
    - Sigmoid
    > &sigma;(x)=1/1+e<sup>-x</sup>
    - Leaky ReLU
    > max(0.1x, x)
    - tanh
    > tanh(x)
    - ReLU
    > max(0, x)
    - Maxout
    > max(&omega;<sup>T</sup><sub>1</sub>x+b<sub>1</sub>,&omega;<sup>T</sup><sub>2</sub>x+b<sub>2</sub>)
    - ELU
    > x >= 0 ? x : &alpha;(e<sup>x</sup>-1)

  - Softmax
    - Make logit scores into probabilities

    <img src=https://cdn-images-1.medium.com/max/906/1*670CdxchunD-yAuUWdI7Bw.png>

